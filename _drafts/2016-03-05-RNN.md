---
layout: "post"
title: "Recurrent Neural Network"
excerpt: "RNN, LSTM"
date: "2016-03-05 10:00:00"
---

RNN을 공부하던중, Andrej Karpathy의 [The Unreasonable Effectiveness of Recurrent Neural Networks](http://karpathy.github.io/2015/05/21/rnn-effectiveness/) 를 보고 정리하고자 싶어 LSTM에 대한 내용과 RNN에 대한 부가적인 설명을 덧붙여서 포스팅 하려고 한다.

---

Recurrent Network가 특별한 이유가 무엇일까? 우리가(내가) 공부했던 Neural Network나 혹은 CNN은 너무 제한적이다. 그러니까 예를들어 CNN은 입력값으로 고정된 크기의 벡터만 받을 수 있으며(이미지) 고정된 계산 스텝(레이어의 개수)을 통해서 고정된 크기의 벡터를 출력한다. 반면 RNN은 벡터의 시퀀스를 처리할 수 있다는 점에서 일반적인 neural network 보다 자유롭다.

<div class="imgcap">
<img src="/assets/RNN/varient.jpg">
</div>

one-to-one은 일반적인 neural net이다. 고정된 크기의 벡터를 입력받고 출력하며, 이미지 분류 문제가 여기에 속한다. one-to-many는 입력은 고정된 크기의 벡터를 받지만 벡터의 시퀀스를 출력하며, 이미지를 입력받고 이를 captioning하는 문제를 이 모델을 통해 풀 수 있다. many-to-one은 텍스트를 입력받고 감정 분석 하는 문제를 예를 들수 있겠고, 왼쪽의 many-to-many는 기계 번역을 처리할 수 있다. 오른쪽의 many-to-many 모델은 입력과 출력간의 싱크가 맞춰져있는데 비디오를 보고 분류하는 문제를 이 모델을 활용하여 풀 수 있다.

입력 혹은 출력에 시퀀스가 주어지는것은 현실적으로 드문게 아닐까 하는 의문이 들 수 있다. 물론 어쩌면 그럴수도 있겠지만, RNN은 입력/출력의 벡터가 고정된 크기에도 잘 동작한다. 아래의 그림들은 DeepMind에서 발표한 논문들인데, 왼쪽은 recurrent network를 이용해서 house number를 읽는 일을 하는데 (아직 논문을 읽지 않아 정확히는 모르겠지만) attention을 이용해서 사진의 왼쪽부터 오른쪽으로 훑으면서 읽는 모습을 볼 수 있다. 반면 오른쪽은 recurrent network가 house number를 "그리는" 것이다.

<div class="imgcap">
<img src="/assets/RNN/house1.gif" style="max-width:49%">
<img src="/assets/RNN/house2.gif" style="max-width:49%">
</div>

이런 예시들은 recurrent network가 고정된 크기의 입/출력 벡터를 가지더라도 효과적으로 동작 할 수 있음을 보여준다.

## RNN computation
RNN은 다른 네트워크들과 비슷하게 입력으로 벡터 `x`를 받고, `y`를 출력한다. 하지만 다른점은 출력값은 그 time step에서의 입력과 예전 **모든 과거들의 값들에 영향**을 받는다는 것이다.

```python
rnn = RNN()
y = rnn.step(x) # x는 입력 벡터, y는 RNN의 출력 벡터이다.
```

그래서 RNN은 매 time step마다 업데이트되는 hidden state를 가지고 있다. 여기서는 간단하게 hidden state `h`를 한개만 가지고 있다고 가정해보자.

```python
class RNN:
  # ...
  def step(self, x):
    # hidden state를 업데이트
    self.h = np.tanh(np.dot(self.W_hh, self.h) + np.dot(self.W_xh, x))
    # 출력 벡터 계산
    y = np.dot(self.W_hy, self.h)

    return y
```

위 코드는 RNN의 foward pass를 간략하게 작성한 것이다. parameter는 `W_hh, W_xh, W_hy` 3개의 행렬이 있고 hidden state `self.h`는 zero 벡터로 초기화 하였으며, `np.tanh`는 `[-1, 1]`의 범위를 가지는 non-linearlity를 의미한다. `np.tanh` 함수 내부에는 두 식의 합으로 구성되어 있는데, `np.dot(self.W_hh, self.h)`는 이전의 hidden state를 기반으로 하며 `np.dot(self.W_xh, x))`는 현재 입력값을 기반으로 계산된다. 위 코드를 수식으로 표현하면 다음과 같다.

<div>
\begin{align}
h _t = tanh(W _{hh} h _{t-1} + W _{xh} x _t)
\end{align}
</div>

## Character-Level Language Models
이제 RNN을 이용해서 character-level language model을 학습시켜보자. 만약 RNN에 텍스트 뭉치를 주면 RNN은 이전까지 어떤 글자들이 나왔는지를 살펴 본 뒤, 다음 글자(character)가 나올 확률 분포를 계산해준다. 그럼 확률 분포중 가장 확률이 높은 분포인 글자를 택한다면 학습시킨 문장과 비슷한 형태를 가지는 새로운 문장 혹은 글을 만들어낼 수 있다.

한가지 예를 들어보자. 만약 사용할 수 있는 글자가 오직 [h,e,l,o]만 있고, RNN에 "hello"라는 글자를 학습시켜야 한다고 가정하자. 이 때 RNN에 전달할 입력값과 받을 출력값은 one-hot 벡터의 형태로 인코딩된다. 예를 들어 h는 [1,0,0,0], "e"는 [0,1,0,0] 의 형태로 나타낼 수 있다. 우리는 RNN이 "hello"라는 단어를 예측할 수 있도록 학습하고자 하기 때문에 만약 입력값으로 [1,0,0,0] 이 들어오면 출력은 [0,1,0,0] 이 나오고, [0,1,0,0] 은 [0,0,1,0] 과 같이 다음에 나올 글자를 예측하게 만들어야 한다.

<div class="imgcap">
<img src="/assets/RNN/charseq.jpg" style="max-height:400px">
</div>

`hidden_layer`의 값과 weight `W`들은 랜덤하게 초기화 한 후 "hello"를 RNN에 입력하면 위와 같은 결과가 나온다. 가장 처음 time step의 target은 "e"지만 랜덤하게 초기화하였기 때문에 결과값으로 "o"가 출력되었다. 이처럼 RNN의 성능을 향상시키기 위해서는 그림에서 초록색 숫자를 최대한 크게 만들고, 빨간색 숫자는 최대한 작게 만들어야 한다. loss function을 정할 때 가장 많이 쓰는 방법은 cross-entropy이다.

<div>
\begin{align}
L(y, \hat{y}) = - \sum_{t} y _t \ log \ \hat{y _t}
\end{align}
</div>

$y$는 실제 값이며 $o$는 예상된 값을 의미한다. 예측한 결과값인 벡터 $o$는 softmax를 거친 뒤 다음 시퀀스는 어떤 글자가 나올지 예측하게 된다. 그리고 만약 RNN이 loss function에 의해 backprop을 한 번 하게 되면 지금보다는 더 나은 성능 (더 작은 loss)을 기대할 수 있으며 더 많이 backprop을 진행 할 수록 성능은 높아지고 loss값은 줄어들 것이다.

## Fun with RNNs

### Paul Graham 생성기
사실 Paul Graham이 누군지도 처음 들었긴 하지만 어쨌거나 karpathy는 이 사람이 쓴 에세이를 모아서 학습 데이터에 사용해 보았다고 한다. 데이터의 양은 1MB정도고 글자수는 약 100만개 정도라는데 사실 이정도면 적은 양의 데이터라고 볼 수 있겠다. 학습시킨 모델을 살펴보면, 2-layer의 LSTM 구조를 가지고 있고 각 레이어는 512개의 hidden node를 가지고 있다. 0.5의 확률로 dropout을 하였으며, 

## 레퍼런스
[Andrej Karpathy의 블로그](http://karpathy.github.io/2015/05/21/rnn-effectiveness/)
