---
layout: "post"
title: "임시 정리"
excerpt: ""
date: "2016-03-05 10:00:00"
---

# Application of Convnet
## Classification
<div class="imgcap">
<img src="/assets/class.png">
</div>
대부분의 연구는 ImageNet의 이미지셋을 이용하여 classification의 5-error rate를 줄이는 방향

[ImageNet Classification with Deep Convolutional Neural Networks](http://papers.nips.cc/paper/4824-imagenet-classification-with-deep-convolutional-neural-networks.pdf)  
2012년 딥러닝의 폭발을 이끈 AlexNet  
[Very Deep Convolutional Networks for Large-Scale Image Recognition](http://arxiv.org/abs/1409.1556)  
2014년 ILSVRC에서 2위를 차지한 네트워크, AlexNet보다 간단한 구조, 작은 필터의 사용이 특징  
[Network In Network](http://arxiv.org/abs/1312.4400)  
Average pooling, 1x1 conv filter등을 제안, ILSVRC에 두각을 내진 않았지만 제안한 내용이 GoogLeNet, ResNet등 state-of-the-art 네트워크에 많이 쓰임   
[Delving Deep into Rectifiers: Surpassing Human-Level Performance on ImageNet Classification](http://arxiv.org/abs/1502.01852)  
MSRA에서 제시한 PReLU-net, ReLU를 개선한 PReLU와 weight의 초기화를 Xavier 초기화를 이용하여 gradient vanishing 문제를 해결함  
[Deep Residual Learning for Image Recognition](http://arxiv.org/abs/1512.03385)  
Residual Learning 제시, LSTM과 비슷한 구조로 네트워크의 레이어의 수를 100개 이상 (이론상으로 ~1000개) 늘려 2015년 state-of-the-art를 차지

## Detection, Localization
<div class="imgcap">
<img src="/assets/detection.png">
</div>
classification에 사용된 pre-trained 모델을 이용해서 detection, localization, segmentation 등에 응용

[OverFeat: Integrated Recognition, Localization and Detection using Convolutional Networks](http://arxiv.org/abs/1312.6229)  
Overfeat 구조  
[Rich feature hierarchies for accurate object detection and semantic segmentation](http://www.cv-foundation.org/openaccess/content_cvpr_2014/html/Girshick_Rich_Feature_Hierarchies_2014_CVPR_paper.html)  
R-CNN, selective search등의 알고리즘을 이용해서 정해진 수의 region을 선택한 뒤 이를 convnet에 입력한 뒤 각각의 출력값을 이용해서 detect  
[Fast r-cnn](http://www.cv-foundation.org/openaccess/content_iccv_2015/html/Girshick_Fast_R-CNN_ICCV_2015_paper.html)  
여러 개의 region을 연산해야 하기 때문에 느린 R-CNN의 구조를 바꾸어 최적화 시킴  

## Super-resolution
[Accurate Image Super-Resolution Using Very Deep Convolutional Networks](http://arxiv.org/abs/1511.04587)

## Segmentation
<div class="imgcap">
<img src="/assets/segmentation.png">
</div>

## Pose estimation
<div class="imgcap">
<img src="/assets/deeppose.png">
</div>
[Deeppose: Human pose estimation via deep neural networks](http://www.cv-foundation.org/openaccess/content_cvpr_2014/html/Toshev_DeepPose_Human_Pose_2014_CVPR_paper.html)

## Others
<div class="imgcap">
<img src="/assets/neural-art.jpg">
</div>
[A Neural Algorithm of Artistic Style](http://arxiv.org/pdf/1508.06576.pdf) - [참고 뉴스](http://news.sbs.co.kr/news/endPage.do?news_id=N1003203149)

**Deepdream**
<div class="imgcap">
<img src="/assets/deepdream.jpg">
</div>
[여기](http://deepdreamgenerator.com)에 직접 사진을 업로드 가능
[참고 자료](http://visla.kr/?p=34947), [참고 자료2](http://nuriwiki.net/wiki/index.php/Google_Deep_Dream#cite_note-1), [참고 자료3](http://www.networkworld.com/article/2974718/software/deep-dream-artificial-intelligence-meets-hallucinations.html)

# Neural Net packages

## Caffe (UCB)
- C++로 만들어졌고, python과 matlab 인터페이스 제공
- NN과 CNN을 fine-tuning할때 좋음 ([Caffe: Model Zoo](https://github.com/BVLC/caffe/wiki/Model-Zoo)에서 AlexNet, VGG, GoogLeNet, ResNet등 유명한 네트워크들의 pre-trained 모델 제공)

### 장점
- feedfoward 네트워크, 특히 transfer learning이나 fine-tuning할 때 좋음 (제공되는 pre-trained 모델이 많음)
- prototxt파일만 수정하면 코드를 추가하지 않아도 모델을 학습시킬수 있음
- python 인터페이스 제공

### 단점
- GPU에 돌아가는 레이어를 추가하기 위해서 C++, CUDA를 이용하여 작성해야함
- RNN을 만들기에 좋지 않은 구조
- prototxt파일을 이용해 네트워크를 정의하기 때문에 ResNet같은 거대한 네트워크를 만들기 번거로움 (ResNet은 prototxt파일이 6000라인)

## Torch (NYU)
- C와 lua로 코드 작성
- 페이스북과 딥마인드에서 사용

### 장점
- GPU에 돌아가는 레이어도 간단한 코드로 작성가능
- 라이브러리 전체가 readable하게 작성됨
- Caffe와 마찬가지로 pre-trained 모델이 많음
- 모듈들을 쉽게 조합해서 새로운 네트워크를 만들기 용이함

### 단점
- Lua를 사용
- Caffe보다 편리성이 떨어짐 (Caffe는 코드 작성없이 모델의 학습이 가능, Torch는 학습코드를 작성해야함)
- Caffe와 마찬가지로 RNN에 부적합

## Theano (Universite de Montreal)
- Keras와 Lasagne라는 high-level wrapper 제공

### 장점
- python, numpy 사용
- computational graph라는 개념을 이용하여 RNN을 작성하기 용이함
- Keras, Lasagne와 같은 high-level wrapper 제공

### 단점
- theano 자체는 로우레벨이고, wrapper를 사용할 경우 디버깅이 힘듬
- pre-train 모델이 적음

## TensorFlow (Google)
- computation graphs를 사용하는 Theano와 유사함
- TensorBoard를 사용하면 visualization이 쉬움 (디버깅이 쉬움)
- multi-GPU와 분산처리(아직 공개x) 제공

### 장점
- pythonm, numpy 사용
- Theano와 마찬가지로 RNN 작성이 용이
- Theano보다 컴파일 타임이 빠름
- visualization이 좋음(Tensorboard)
- data와 모델 병렬성에 관해서는 다른 framework들중 가장 좋음
- 추후 distributed model 제공 예정?

### 단점
- single-GPU는 다른 framework보다 느림
- pre-train 모델이 거의 없음
